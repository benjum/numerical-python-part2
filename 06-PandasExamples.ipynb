{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c62dfbff",
   "metadata": {},
   "source": [
    "## Pandas Examples\n",
    "\n",
    "- **DataFrames**: Powerful 2D labeled data structures (like spreadsheets)\n",
    "- **Series**: 1D labeled arrays\n",
    "- **Data I/O**: Read/write CSV, Excel, SQL, JSON, and more\n",
    "- **Data manipulation**: Filter, sort, group, merge, reshape\n",
    "- **Time series**: Specialized functionality for temporal data\n",
    "- **Built on NumPy**: Fast and efficient\n",
    "\n",
    "Pandas is essential for:\n",
    "- Data cleaning and preparation\n",
    "- Exploratory data analysis\n",
    "- Statistical analysis\n",
    "- Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5191ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 2)\n",
    "\n",
    "# Random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31b4963",
   "metadata": {},
   "source": [
    "## Creating DataFrames and Series\n",
    "\n",
    "### Series: 1D labeled array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5535f2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Series from a list\n",
    "temperatures = pd.Series([22.5, 24.1, 23.8, 21.9, 25.3], \n",
    "                        index=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday'],\n",
    "                        name='Temperature')\n",
    "\n",
    "print(\"Temperature Series:\")\n",
    "print(temperatures)\n",
    "print(f\"\\nMean temperature: {temperatures.mean():.2f}°C\")\n",
    "print(f\"Max temperature: {temperatures.max():.2f}°C on {temperatures.idxmax()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792ba733",
   "metadata": {},
   "source": [
    "### DataFrame: 2D labeled data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf67af74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from a dictionary\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve'],\n",
    "    'Age': [25, 30, 35, 28, 32],\n",
    "    'City': ['New York', 'San Francisco', 'Los Angeles', 'Chicago', 'Boston'],\n",
    "    'Salary': [70000, 85000, 75000, 90000, 82000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Basic DataFrame:\")\n",
    "print(df)\n",
    "print(f\"\\nShape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ad408c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame info and statistics\n",
    "print(\"DataFrame Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4393c2f4",
   "metadata": {},
   "source": [
    "## Data Selection and Indexing\n",
    "\n",
    "Multiple ways to access data in a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791c2ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a single column (returns Series)\n",
    "print(\"Ages:\")\n",
    "print(df['Age'])\n",
    "\n",
    "# Select multiple columns (returns DataFrame)\n",
    "print(\"\\nNames and Salaries:\")\n",
    "print(df[['Name', 'Salary']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d38661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows by position with iloc\n",
    "print(\"First two rows:\")\n",
    "print(df.iloc[0:2])\n",
    "\n",
    "# Select rows by label with loc\n",
    "print(\"\\nRows 0 and 2:\")\n",
    "print(df.loc[[0, 2]])\n",
    "\n",
    "# Select specific cells\n",
    "print(f\"\\nBob's salary: ${df.loc[1, 'Salary']:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca623add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean indexing (filtering)\n",
    "print(\"People with salary > $80,000:\")\n",
    "high_earners = df[df['Salary'] > 80000]\n",
    "print(high_earners)\n",
    "\n",
    "print(\"\\nPeople aged 30+ in California cities:\")\n",
    "filtered = df[(df['Age'] >= 30) & (df['City'].isin(['San Francisco', 'Los Angeles']))]\n",
    "print(filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba12459",
   "metadata": {},
   "source": [
    "## Data Manipulation\n",
    "\n",
    "### Adding and Modifying Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d1a495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new columns\n",
    "df['Bonus'] = df['Salary'] * 0.1\n",
    "df['Total_Compensation'] = df['Salary'] + df['Bonus']\n",
    "df['Experience_Years'] = df['Age'] - 22  # Assuming college graduation at 22\n",
    "\n",
    "print(\"DataFrame with new columns:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdef607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply functions to columns\n",
    "df['Salary_Category'] = df['Salary'].apply(lambda x: 'High' if x > 80000 else 'Medium' if x > 70000 else 'Low')\n",
    "\n",
    "# Using map for simple replacements\n",
    "city_region = {\n",
    "    'New York': 'East',\n",
    "    'San Francisco': 'West',\n",
    "    'Los Angeles': 'West',\n",
    "    'Chicago': 'Midwest',\n",
    "    'Boston': 'East'\n",
    "}\n",
    "df['Region'] = df['City'].map(city_region)\n",
    "\n",
    "print(\"DataFrame with categorical columns:\")\n",
    "print(df[['Name', 'City', 'Region', 'Salary', 'Salary_Category']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5df134c",
   "metadata": {},
   "source": [
    "### Sorting and Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e0f9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by column\n",
    "print(\"Sorted by Salary (descending):\")\n",
    "print(df.sort_values('Salary', ascending=False)[['Name', 'Salary']])\n",
    "\n",
    "# Sort by multiple columns\n",
    "print(\"\\nSorted by Region, then Salary:\")\n",
    "print(df.sort_values(['Region', 'Salary'], ascending=[True, False])[['Name', 'Region', 'Salary']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6611b45a",
   "metadata": {},
   "source": [
    "### Grouping and Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89543e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Region\n",
    "print(\"Statistics by Region:\")\n",
    "region_stats = df.groupby('Region').agg({\n",
    "    'Salary': ['mean', 'min', 'max', 'count'],\n",
    "    'Age': 'mean'\n",
    "})\n",
    "print(region_stats)\n",
    "\n",
    "# Multiple aggregations\n",
    "print(\"\\nSalary Category Summary:\")\n",
    "category_summary = df.groupby('Salary_Category')['Salary'].describe()\n",
    "print(category_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001366b3",
   "metadata": {},
   "source": [
    "## Real-World Dataset: Scientific Measurements\n",
    "\n",
    "Let's create and analyze a realistic scientific dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083a416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic experimental data\n",
    "n_samples = 200\n",
    "\n",
    "# Create realistic scientific data\n",
    "experiments = pd.DataFrame({\n",
    "    'Sample_ID': [f'S{i:03d}' for i in range(n_samples)],\n",
    "    'Treatment': np.random.choice(['Control', 'Drug_A', 'Drug_B', 'Drug_C'], n_samples),\n",
    "    'Concentration': np.random.choice([0, 10, 50, 100], n_samples),  # μM\n",
    "    'Temperature': np.random.normal(37, 0.5, n_samples),  # °C\n",
    "    'pH': np.random.normal(7.4, 0.1, n_samples),\n",
    "    'Response': np.random.normal(50, 15, n_samples),  # Some measurement\n",
    "    'Time_hours': np.random.choice([1, 3, 6, 12, 24], n_samples),\n",
    "    'Batch': np.random.choice(['Batch_1', 'Batch_2', 'Batch_3'], n_samples)\n",
    "})\n",
    "\n",
    "# Add treatment effect to Response\n",
    "treatment_effects = {'Control': 0, 'Drug_A': 15, 'Drug_B': 25, 'Drug_C': 20}\n",
    "experiments['Response'] += experiments['Treatment'].map(treatment_effects)\n",
    "experiments['Response'] += experiments['Concentration'] * 0.2\n",
    "experiments['Response'] = experiments['Response'].clip(lower=0)  # No negative responses\n",
    "\n",
    "print(\"Experimental Dataset:\")\n",
    "print(experiments.head(10))\n",
    "print(f\"\\nDataset shape: {experiments.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2528eb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the dataset\n",
    "print(\"Dataset Summary:\")\n",
    "print(experiments.describe())\n",
    "\n",
    "print(\"\\nTreatment counts:\")\n",
    "print(experiments['Treatment'].value_counts())\n",
    "\n",
    "print(\"\\nMissing values:\")\n",
    "print(experiments.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0aa030",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "### Statistical Analysis by Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95c707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare treatments\n",
    "print(\"Response by Treatment:\")\n",
    "treatment_stats = experiments.groupby('Treatment')['Response'].agg([\n",
    "    'count', 'mean', 'std', 'min', 'max'\n",
    "]).round(2)\n",
    "print(treatment_stats)\n",
    "\n",
    "# Response by concentration\n",
    "print(\"\\nResponse by Concentration:\")\n",
    "conc_stats = experiments.groupby('Concentration')['Response'].agg([\n",
    "    'count', 'mean', 'std'\n",
    "]).round(2)\n",
    "print(conc_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b432673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-tabulation: Treatment vs Concentration\n",
    "print(\"Mean Response by Treatment and Concentration:\")\n",
    "pivot = pd.pivot_table(experiments, \n",
    "                       values='Response', \n",
    "                       index='Treatment', \n",
    "                       columns='Concentration', \n",
    "                       aggfunc='mean')\n",
    "print(pivot.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dad698",
   "metadata": {},
   "source": [
    "### Statistical Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73ade41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-test: Compare Control vs Drug_A\n",
    "control = experiments[experiments['Treatment'] == 'Control']['Response']\n",
    "drug_a = experiments[experiments['Treatment'] == 'Drug_A']['Response']\n",
    "\n",
    "t_stat, p_value = stats.ttest_ind(control, drug_a)\n",
    "\n",
    "print(\"T-test: Control vs Drug_A\")\n",
    "print(f\"  Control mean: {control.mean():.2f} ± {control.std():.2f}\")\n",
    "print(f\"  Drug_A mean: {drug_a.mean():.2f} ± {drug_a.std():.2f}\")\n",
    "print(f\"  t-statistic: {t_stat:.3f}\")\n",
    "print(f\"  p-value: {p_value:.4f}\")\n",
    "print(f\"  Significant at α=0.05: {'Yes' if p_value < 0.05 else 'No'}\")\n",
    "\n",
    "# ANOVA: Compare all treatments\n",
    "groups = [experiments[experiments['Treatment'] == t]['Response'] \n",
    "          for t in experiments['Treatment'].unique()]\n",
    "f_stat, p_value_anova = stats.f_oneway(*groups)\n",
    "\n",
    "print(f\"\\nANOVA: All treatments\")\n",
    "print(f\"  F-statistic: {f_stat:.3f}\")\n",
    "print(f\"  p-value: {p_value_anova:.4f}\")\n",
    "print(f\"  Significant difference between treatments: {'Yes' if p_value_anova < 0.05 else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce7e5d1",
   "metadata": {},
   "source": [
    "### Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a564285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "print(\"Correlation Matrix:\")\n",
    "correlation = experiments[['Temperature', 'pH', 'Concentration', 'Response', 'Time_hours']].corr()\n",
    "print(correlation.round(3))\n",
    "\n",
    "# Visualize correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(correlation, cmap='RdBu_r', aspect='auto', vmin=-1, vmax=1)\n",
    "plt.colorbar(label='Correlation coefficient')\n",
    "plt.xticks(range(len(correlation.columns)), correlation.columns, rotation=45, ha='right')\n",
    "plt.yticks(range(len(correlation.columns)), correlation.columns)\n",
    "plt.title('Correlation Matrix Heatmap', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add correlation values to cells\n",
    "for i in range(len(correlation.columns)):\n",
    "    for j in range(len(correlation.columns)):\n",
    "        plt.text(j, i, f'{correlation.iloc[i, j]:.2f}', \n",
    "                ha='center', va='center', color='black', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338a60fc",
   "metadata": {},
   "source": [
    "## Data Visualization with Pandas\n",
    "\n",
    "Pandas has built-in plotting that works seamlessly with Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4839e4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots by treatment\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "experiments.boxplot(column='Response', by='Treatment', ax=axes[0])\n",
    "axes[0].set_title('Response by Treatment')\n",
    "axes[0].set_xlabel('Treatment')\n",
    "axes[0].set_ylabel('Response')\n",
    "plt.sca(axes[0])\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "experiments.boxplot(column='Response', by='Concentration', ax=axes[1])\n",
    "axes[1].set_title('Response by Concentration')\n",
    "axes[1].set_xlabel('Concentration (μM)')\n",
    "axes[1].set_ylabel('Response')\n",
    "\n",
    "plt.suptitle('')  # Remove default title\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539dac97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot: Mean response by treatment with error bars\n",
    "treatment_summary = experiments.groupby('Treatment')['Response'].agg(['mean', 'std', 'sem'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "treatment_summary['mean'].plot(kind='bar', ax=ax, color=['#3498db', '#e74c3c', '#2ecc71', '#f39c12'],\n",
    "                                yerr=treatment_summary['sem'], capsize=5, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "ax.set_xlabel('Treatment', fontsize=12)\n",
    "ax.set_ylabel('Mean Response', fontsize=12)\n",
    "ax.set_title('Mean Response by Treatment (with SEM)', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add value labels\n",
    "for i, (idx, row) in enumerate(treatment_summary.iterrows()):\n",
    "    ax.text(i, row['mean'] + row['sem'] + 2, f\"{row['mean']:.1f}\", \n",
    "            ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33e9f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot: Response vs Concentration, colored by Treatment\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "treatments = experiments['Treatment'].unique()\n",
    "colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12']\n",
    "\n",
    "for treatment, color in zip(treatments, colors):\n",
    "    subset = experiments[experiments['Treatment'] == treatment]\n",
    "    ax.scatter(subset['Concentration'], subset['Response'], \n",
    "              label=treatment, alpha=0.6, s=80, color=color, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "ax.set_xlabel('Concentration (μM)', fontsize=12)\n",
    "ax.set_ylabel('Response', fontsize=12)\n",
    "ax.set_title('Response vs Concentration by Treatment', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e572bce",
   "metadata": {},
   "source": [
    "## Time Series Analysis\n",
    "\n",
    "Create a time-based dataset and analyze trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee648925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time series data\n",
    "dates = pd.date_range(start='2025-01-01', end='2025-12-31', freq='D')\n",
    "n_days = len(dates)\n",
    "\n",
    "# Simulate seasonal sales data\n",
    "trend = np.linspace(100, 150, n_days)  # Upward trend\n",
    "seasonal = 30 * np.sin(2 * np.pi * np.arange(n_days) / 365)  # Annual seasonality\n",
    "noise = np.random.randn(n_days) * 5\n",
    "sales = trend + seasonal + noise\n",
    "\n",
    "sales_data = pd.DataFrame({\n",
    "    'Date': dates,\n",
    "    'Sales': sales,\n",
    "    'Day_of_Week': dates.day_name(),\n",
    "    'Month': dates.month_name(),\n",
    "    'Quarter': dates.quarter\n",
    "})\n",
    "\n",
    "# Set Date as index\n",
    "sales_data.set_index('Date', inplace=True)\n",
    "\n",
    "print(\"Time Series Data:\")\n",
    "print(sales_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b899bbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series visualization\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Daily sales\n",
    "sales_data['Sales'].plot(ax=axes[0], linewidth=1, alpha=0.7, color='blue')\n",
    "sales_data['Sales'].rolling(window=30).mean().plot(ax=axes[0], linewidth=2, color='red', label='30-day MA')\n",
    "axes[0].set_xlabel('Date', fontsize=12)\n",
    "axes[0].set_ylabel('Sales', fontsize=12)\n",
    "axes[0].set_title('Daily Sales with 30-Day Moving Average', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Monthly aggregation\n",
    "monthly_sales = sales_data.resample('ME')['Sales'].agg(['mean', 'sum', 'std'])\n",
    "monthly_sales['mean'].plot(kind='bar', ax=axes[1], color='teal', alpha=0.7, edgecolor='black')\n",
    "axes[1].set_xlabel('Month', fontsize=12)\n",
    "axes[1].set_ylabel('Average Sales', fontsize=12)\n",
    "axes[1].set_title('Monthly Average Sales', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nMonthly Statistics:\")\n",
    "print(monthly_sales.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93897a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze by day of week\n",
    "dow_sales = sales_data.groupby('Day_of_Week')['Sales'].agg(['mean', 'std', 'count'])\n",
    "\n",
    "# Order by day of week\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "dow_sales = dow_sales.reindex(day_order)\n",
    "\n",
    "print(\"Sales by Day of Week:\")\n",
    "print(dow_sales.round(2))\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "dow_sales['mean'].plot(kind='bar', ax=ax, color='coral', alpha=0.7, \n",
    "                       yerr=dow_sales['std'], capsize=5, edgecolor='black', linewidth=1.5)\n",
    "ax.set_xlabel('Day of Week', fontsize=12)\n",
    "ax.set_ylabel('Average Sales', fontsize=12)\n",
    "ax.set_title('Average Sales by Day of Week', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80183fc2",
   "metadata": {},
   "source": [
    "## Analysis Workflow\n",
    "\n",
    "Combining NumPy, SciPy, Matplotlib, and Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d97282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive dataset\n",
    "np.random.seed(42)\n",
    "n = 100\n",
    "\n",
    "# Simulate enzyme kinetics experiment (Michaelis-Menten)\n",
    "substrate_conc = np.linspace(0, 100, n)  # μM\n",
    "Vmax = 80  # Maximum velocity\n",
    "Km = 20    # Michaelis constant\n",
    "\n",
    "# Michaelis-Menten equation: v = Vmax * [S] / (Km + [S])\n",
    "velocity_true = Vmax * substrate_conc / (Km + substrate_conc)\n",
    "velocity_measured = velocity_true + np.random.normal(0, 3, n)\n",
    "\n",
    "# Create DataFrame\n",
    "kinetics = pd.DataFrame({\n",
    "    'Substrate_uM': substrate_conc,\n",
    "    'Velocity': velocity_measured,\n",
    "    'Temperature': np.random.normal(25, 0.5, n),\n",
    "    'pH': np.random.normal(7.0, 0.1, n),\n",
    "    'Replicate': np.random.choice(['A', 'B', 'C'], n)\n",
    "})\n",
    "\n",
    "print(\"Enzyme Kinetics Dataset:\")\n",
    "print(kinetics.head(10))\n",
    "print(f\"\\nDataset shape: {kinetics.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f470bb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Exploratory Data Analysis\n",
    "print(\"Descriptive Statistics:\")\n",
    "print(kinetics.describe())\n",
    "\n",
    "print(\"\\nCorrelation with Velocity:\")\n",
    "correlations = kinetics.corr(numeric_only=True)['Velocity'].sort_values(ascending=False)\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af7f088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Curve Fitting using SciPy\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def michaelis_menten(S, Vmax, Km):\n",
    "    \"\"\"Michaelis-Menten equation\"\"\"\n",
    "    return Vmax * S / (Km + S)\n",
    "\n",
    "# Fit the model\n",
    "params, covariance = curve_fit(michaelis_menten, \n",
    "                               kinetics['Substrate_uM'], \n",
    "                               kinetics['Velocity'],\n",
    "                               p0=[70, 15])\n",
    "\n",
    "Vmax_fit, Km_fit = params\n",
    "param_errors = np.sqrt(np.diag(covariance))\n",
    "\n",
    "print(\"Fitted Parameters:\")\n",
    "print(f\"  Vmax = {Vmax_fit:.2f} ± {param_errors[0]:.2f} (true: {Vmax})\")\n",
    "print(f\"  Km = {Km_fit:.2f} ± {param_errors[1]:.2f} (true: {Km})\")\n",
    "\n",
    "# Add fitted values to DataFrame\n",
    "kinetics['Velocity_Fit'] = michaelis_menten(kinetics['Substrate_uM'], Vmax_fit, Km_fit)\n",
    "kinetics['Residuals'] = kinetics['Velocity'] - kinetics['Velocity_Fit']\n",
    "\n",
    "# Calculate R²\n",
    "ss_res = np.sum(kinetics['Residuals']**2)\n",
    "ss_tot = np.sum((kinetics['Velocity'] - kinetics['Velocity'].mean())**2)\n",
    "r_squared = 1 - (ss_res / ss_tot)\n",
    "print(f\"\\nR² = {r_squared:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecefb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Comprehensive Visualization\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Plot 1: Main kinetics plot with fit\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "ax1.scatter(kinetics['Substrate_uM'], kinetics['Velocity'], \n",
    "           alpha=0.5, s=50, label='Experimental data', color='blue', edgecolors='black', linewidth=0.5)\n",
    "substrate_smooth = np.linspace(0, 100, 200)\n",
    "velocity_smooth = michaelis_menten(substrate_smooth, Vmax_fit, Km_fit)\n",
    "ax1.plot(substrate_smooth, velocity_smooth, 'r-', linewidth=3, \n",
    "        label=f'Fit: Vmax={Vmax_fit:.1f}, Km={Km_fit:.1f}')\n",
    "ax1.axhline(y=Vmax_fit/2, color='green', linestyle='--', linewidth=2, alpha=0.7, label=f'Km = {Km_fit:.1f} μM')\n",
    "ax1.axvline(x=Km_fit, color='green', linestyle='--', linewidth=2, alpha=0.7)\n",
    "ax1.set_xlabel('Substrate Concentration (μM)', fontsize=12)\n",
    "ax1.set_ylabel('Velocity (μM/min)', fontsize=12)\n",
    "ax1.set_title('Enzyme Kinetics: Michaelis-Menten Fit', fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Residuals plot\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "ax2.scatter(kinetics['Velocity_Fit'], kinetics['Residuals'], alpha=0.5, s=50, color='purple')\n",
    "ax2.axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "ax2.set_xlabel('Fitted Velocity', fontsize=11)\n",
    "ax2.set_ylabel('Residuals', fontsize=11)\n",
    "ax2.set_title('Residuals Plot', fontsize=12)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Residuals histogram\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "ax3.hist(kinetics['Residuals'], bins=20, color='coral', edgecolor='black', alpha=0.7)\n",
    "ax3.axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "ax3.set_xlabel('Residuals', fontsize=11)\n",
    "ax3.set_ylabel('Frequency', fontsize=11)\n",
    "ax3.set_title('Distribution of Residuals', fontsize=12)\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 4: Velocity by Replicate\n",
    "ax4 = fig.add_subplot(gs[1, 2])\n",
    "kinetics.boxplot(column='Velocity', by='Replicate', ax=ax4)\n",
    "ax4.set_xlabel('Replicate', fontsize=11)\n",
    "ax4.set_ylabel('Velocity', fontsize=11)\n",
    "ax4.set_title('Velocity by Replicate', fontsize=12)\n",
    "plt.sca(ax4)\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Plot 5: Lineweaver-Burk plot (1/v vs 1/[S])\n",
    "ax5 = fig.add_subplot(gs[2, 0])\n",
    "# Remove zero substrate values for Lineweaver-Burk\n",
    "lb_data = kinetics[kinetics['Substrate_uM'] > 0].copy()\n",
    "lb_data['1/S'] = 1 / lb_data['Substrate_uM']\n",
    "lb_data['1/v'] = 1 / lb_data['Velocity']\n",
    "ax5.scatter(lb_data['1/S'], lb_data['1/v'], alpha=0.5, s=50, color='orange')\n",
    "# Fit line\n",
    "lb_fit = np.polyfit(lb_data['1/S'], lb_data['1/v'], 1)\n",
    "lb_line = np.poly1d(lb_fit)\n",
    "x_lb = np.linspace(lb_data['1/S'].min(), lb_data['1/S'].max(), 100)\n",
    "ax5.plot(x_lb, lb_line(x_lb), 'r-', linewidth=2)\n",
    "ax5.set_xlabel('1/[S] (μM⁻¹)', fontsize=11)\n",
    "ax5.set_ylabel('1/v (min/μM)', fontsize=11)\n",
    "ax5.set_title('Lineweaver-Burk Plot', fontsize=12)\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 6: Summary statistics table\n",
    "ax6 = fig.add_subplot(gs[2, 1:])\n",
    "ax6.axis('tight')\n",
    "ax6.axis('off')\n",
    "summary_data = [\n",
    "    ['Parameter', 'Value'],\n",
    "    ['Vmax (fitted)', f'{Vmax_fit:.2f} ± {param_errors[0]:.2f}'],\n",
    "    ['Km (fitted)', f'{Km_fit:.2f} ± {param_errors[1]:.2f}'],\n",
    "    ['R²', f'{r_squared:.4f}'],\n",
    "    ['RMSE', f'{np.sqrt(np.mean(kinetics[\"Residuals\"]**2)):.3f}'],\n",
    "    ['Mean Velocity', f'{kinetics[\"Velocity\"].mean():.2f} ± {kinetics[\"Velocity\"].std():.2f}'],\n",
    "    ['N samples', f'{len(kinetics)}'],\n",
    "]\n",
    "table = ax6.table(cellText=summary_data, cellLoc='left', loc='center',\n",
    "                 colWidths=[0.4, 0.4])\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(11)\n",
    "table.scale(1, 2)\n",
    "# Style header row\n",
    "for i in range(2):\n",
    "    table[(0, i)].set_facecolor('#3498db')\n",
    "    table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "ax6.set_title('Summary Statistics', fontsize=12, fontweight='bold', pad=20)\n",
    "\n",
    "plt.suptitle('Complete Enzyme Kinetics Analysis', fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be7dda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Statistical Analysis\n",
    "print(\"Statistical Analysis:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Compare replicates\n",
    "print(\"\\nVelocity by Replicate:\")\n",
    "for rep in ['A', 'B', 'C']:\n",
    "    rep_data = kinetics[kinetics['Replicate'] == rep]['Velocity']\n",
    "    print(f\"  Replicate {rep}: {rep_data.mean():.2f} ± {rep_data.std():.2f} (n={len(rep_data)})\")\n",
    "\n",
    "# ANOVA to test if replicates are different\n",
    "groups = [kinetics[kinetics['Replicate'] == rep]['Velocity'].values \n",
    "          for rep in ['A', 'B', 'C']]\n",
    "f_stat, p_value = stats.f_oneway(*groups)\n",
    "print(f\"\\nANOVA test for replicate differences:\")\n",
    "print(f\"  F-statistic: {f_stat:.3f}\")\n",
    "print(f\"  p-value: {p_value:.4f}\")\n",
    "print(f\"  Conclusion: {'Significant difference' if p_value < 0.05 else 'No significant difference'} (α=0.05)\")\n",
    "\n",
    "# Normality test on residuals\n",
    "stat, p_norm = stats.normaltest(kinetics['Residuals'])\n",
    "print(f\"\\nNormality test on residuals:\")\n",
    "print(f\"  Test statistic: {stat:.3f}\")\n",
    "print(f\"  p-value: {p_norm:.4f}\")\n",
    "print(f\"  Residuals are {'normally distributed' if p_norm > 0.05 else 'not normally distributed'} (α=0.05)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
